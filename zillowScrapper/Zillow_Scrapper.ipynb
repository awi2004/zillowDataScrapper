{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from selenium import webdriver\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "class ZillowData:\n",
    "    \"\"\"\n",
    "    Zillow data scrapper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, driver, chromedriver, url):\n",
    "        \"\"\"\n",
    "        Contructor\n",
    "        \"\"\"\n",
    "        self.driver = driver\n",
    "        self.chromedriver = chromedriver\n",
    "        self.url = url\n",
    "\n",
    "    def get_house_links(self, url, driver, pages=20):\n",
    "        \"\"\"\n",
    "        Function to fetch list of house links on all the defined pages.\n",
    "        :param url: link of the page.\n",
    "        :param driver: selenium driver instance.\n",
    "        :param pages: how many pages to scrape the listing.\n",
    "        :return: list of house links on all the defined pages.\n",
    "        \"\"\"\n",
    "        # list to store links of houses on desired pages\n",
    "        house_links = []\n",
    "        try:\n",
    "            for i in range(0, pages):\n",
    "                # set url for each page by appending _p/ to base_url\n",
    "                # for exaple to navigate to page 2: url+'2'+'_p/' i.e https://www.zillow.com/new-york-ny/2_p\n",
    "                self.url = self.url + str(i + 1) + '_p/'\n",
    "\n",
    "                # navigate to page\n",
    "                self.driver.get(url)\n",
    "                # sleep for N secs\n",
    "                time.sleep(3)\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                # get the tags for listings\n",
    "                listings = soup.find_all(\"a\", class_=\"list-card-link list-card-link-top-margin list-card-img\")\n",
    "\n",
    "                # get href or link from listings\n",
    "                page_data = [row['href'] for row in listings]\n",
    "                print(\"listing of houses on page  \"+ str(i+1)+ \" is \" + str(len(page_data)))\n",
    "\n",
    "                # store page links into the list\n",
    "                house_links.append(page_data)\n",
    "                time.sleep(4)\n",
    "\n",
    "            return [j for i in house_links for j in i]  # flatten and resturn the house links as list.\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "    def get_html_data(self, base_url):\n",
    "        \"\"\"\n",
    "        Function to  extract html data of the page using BeautifulSoup\n",
    "        :param base_url: link of the particular house on the page listings.\n",
    "        :return: extracted data of html page with all tags.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # navigate to page\n",
    "            self.driver.get(base_url)\n",
    "            time.sleep(3)\n",
    "            # extract html data of the page using BeautifulSoup\n",
    "            self.soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            # driver.close()\n",
    "            return self.soup\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "    def get_num_beds(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get number of bed, bathroom and size of apartment in sqfeet.\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: umber of bed, bathroom and size of apartment in sqfeet.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information about the beds, bathroom,flat size.\n",
    "            html_data = self.soup.find_all(\"span\", class_='ds-bed-bath-living-area')\n",
    "            # extract bed info\n",
    "            bedroom = html_data[0].text.split()[0]\n",
    "            # extract bathroom info\n",
    "            bathroom = html_data[1].text.split()[0]\n",
    "            # extract apartment size\n",
    "            size = html_data[2].text.split()[0]\n",
    "            return bedroom, bathroom, size\n",
    "        except:\n",
    "            return 'None', 'None', 'None'\n",
    "\n",
    "    def get_addresss(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get address of the listing.\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: address and city of the apartment.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information about the address.\n",
    "            html_data = self.soup.find_all(\"h1\",\n",
    "                                           class_='Text-c11n-8-18-0__aiai24-0 StyledHeading-c11n-8-18-0__ktujwe-0 efSAZl')\n",
    "            # extract address of the apartment\n",
    "            address = html_data[0].text.split(',')[0] + ' ' + html_data[0].text.split(',')[1].rsplit('\\xa0')[1] \\\n",
    "                      + html_data[0].text.split(',')[2]\n",
    "            # extract city of the apartment\n",
    "            city = html_data[0].text.split(',')[1].rsplit('\\xa0')[1]\n",
    "            return address, city\n",
    "        except:\n",
    "            return 'None', 'None'\n",
    "\n",
    "    def get_ad_days_views(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get number of days and views for the ad\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: number of days and views for the ad\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information how long ad listed on Zillow page.\n",
    "            html_data = self.soup.find_all(\"div\", class_='Text-c11n-8-18-0__aiai24-0 einFCw')\n",
    "            # extract number of days of ad\n",
    "            zillow_days = html_data[0].text.split()[0]\n",
    "            # extract number of views for the ad\n",
    "            views = html_data[1].text.split()[0]\n",
    "            return zillow_days, views\n",
    "        except:\n",
    "            return 'None', 'None'\n",
    "\n",
    "    def get_price(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get price of the apartment\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: price of the apartment\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information apartment price.\n",
    "            html_data = self.soup.find_all(\"h4\",\n",
    "                                           class_='Text-c11n-8-18-0__aiai24-0 StyledHeading-c11n-8-18-0__ktujwe-0 gcaUyc sc-pHIBf jLwdeZ')\n",
    "            # extract price of the apartment\n",
    "            price = html_data[0].text.split()[0].rsplit('$')[1]\n",
    "            return price\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "    def get_type_of_ad(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get ad type.\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: ad type.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information type of ad.\n",
    "            html_data = self.soup.find_all(\"span\", class_='sc-pYA-dN ivRwcz ds-status-details')\n",
    "            # extract ad type.\n",
    "            ad_type = html_data[0].text\n",
    "            return ad_type\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "    def get_company(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get company or broker who listed the ad.\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: company or broker who listed the ad.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information company/broker listed the ad.\n",
    "            html_data = soup.find_all(\"strong\", class_='Text-c11n-8-18-0__aiai24-0 dokllX')\n",
    "            # extract commpany or broker info\n",
    "            company = html_data[0].text\n",
    "            return company\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "    def get_agent(self, soup):\n",
    "        \"\"\"\n",
    "        Function to get agent or owner  who listed the ad.\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :return: agent or owner  who listed the ad.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # extract data of the page which holds information agent or owner who listed the ad.\n",
    "            html_data = self.soup.find_all(\"p\", class_='Text-c11n-8-18-0__aiai24-0 foiYRz')\n",
    "            # extract agent or owner info\n",
    "            agent = html_data[0].text\n",
    "            return agent\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "    def get_zillow_data(self, soup, link):\n",
    "        \"\"\"\n",
    "        Function to get all the features of a house.\n",
    "        :param soup: extracted html data of a  page with all tags.\n",
    "        :param link: link of the house from which we extract data.\n",
    "        :return: list containing all the features of a house.\n",
    "        \"\"\"\n",
    "\n",
    "        # store all the\n",
    "        zillow_house_data = []\n",
    "        bedroom, bathroom, size = self.get_num_beds(self.soup)\n",
    "        address, city = self.get_addresss(self.soup)\n",
    "        zillow_days, views = self.get_ad_days_views(self.soup)\n",
    "        price = self.get_price(self.soup)\n",
    "        ad_type = self.get_type_of_ad(self.soup)\n",
    "        company = self.get_company(self.soup)\n",
    "        agent = self.get_agent(self.soup)\n",
    "\n",
    "        zillow_house_data.append(\n",
    "            [bedroom, bathroom, size, address, city, zillow_days, views, price, ad_type, company, agent, link])\n",
    "        return zillow_house_data\n",
    "\n",
    "    def get_all_data(self, chromedriver, driver, pages=20):\n",
    "        \"\"\"\n",
    "        :param chromedriver: chrome drive path to run url and extract data.\n",
    "        :param driver: driver instance to use selenium.\n",
    "        :param pages: number of pages to scrape.\n",
    "        :return: pandas dataframe containing houses  information.\n",
    "        \"\"\"\n",
    "        print('chromedriver path: {}'.format(self.chromedriver))\n",
    "        sys.path.append(self.chromedriver)\n",
    "        # self.driver = webdriver.Chrome(self.chromedriver)\n",
    "        houses = self.get_house_links(self.url, self.driver, pages)\n",
    "        print(\"------calculations house links done--------\")\n",
    "        zillow_data = []\n",
    "        for i in range(0, len(houses)):\n",
    "            # driver = webdriver.Chrome(chromedriver)\n",
    "            soup = self.get_html_data(houses[i])\n",
    "            # time.sleep(3)\n",
    "            zillow_data.append(self.get_zillow_data(soup, houses[i]))\n",
    "            time.sleep(4)\n",
    "\n",
    "        with open('zillow_data_1000.pkl', 'wb') as f:\n",
    "            pickle.dump(zillow_data, f)\n",
    "        df = pd.DataFrame([j for i in zillow_data for j in i])\n",
    "        columns = ['bedroom', 'bathroom', 'size', 'address', 'city', 'zillow_days', 'views', 'price', 'ad_type',\n",
    "                   'company', 'agent', 'link']\n",
    "        df.columns = columns\n",
    "        df.to_csv('zillow_data_26.csv', index=False)\n",
    "        print(\"-----dataframe crated ------\")\n",
    "        self.driver.close()\n",
    "        return df\n",
    "\n",
    "    def stat_of_data(self, df):\n",
    "        \"\"\"\n",
    "        Function to print statics about the scraped data\n",
    "        :param df: dataframe which holds all the scraped data\n",
    "        :return: nothing.\n",
    "        \"\"\"\n",
    "        print('Number of unique properties per  page {}'.format(40))\n",
    "        print('Number of unique properties on all  pages {}'.format(df['link'].nunique()))\n",
    "        #print('Number of unique properties on all 25 pages is ')\n",
    "        print('Number of properties per type of the ad   ')\n",
    "        print(df.ad_type.value_counts())\n",
    "        print('        ')\n",
    "\n",
    "        print('Number of properties per company/broker  ')\n",
    "        print(df.agent.value_counts())\n",
    "\n",
    "        df['price'] = df['price'].apply(lambda x: x.replace(',', ''))\n",
    "        df['size'] = df['size'].apply(lambda x: x.replace(',', '') if x != 'None' else '0')\n",
    "        df['size'] = df['size'].apply(lambda x: x.replace(',', '') if x != '--' else '0')\n",
    "        print('Average price (in total): ${} '.format(np.average(df['price'].astype(int))))\n",
    "        print('Average price per sq.ft: ${} '.format(\n",
    "            round((np.average(df['price'].astype(int)) / np.average(df['size'].astype(int))), 4)))\n",
    "        results={'Number of unique properties per  page ': 40,\n",
    "                'Number of properties per page ': df['link'].nunique(),\n",
    "                'Number of properties per type of the ad   ': df.ad_type.value_counts(),\n",
    "                'Number of properties per company/broker  ': df.agent.value_counts(),\n",
    "                'Average price (in total)$: ':np.average(df['price'].astype(int)),\n",
    "                'Average price per sq.ft$: ':round((np.average(df['price'].astype(int)) / np.average(df['size'].astype(int))), 4)}\n",
    "        print(type(results))\n",
    "        with open('results.txt', 'w') as file:\n",
    "            file.write(str(results))\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing on a single page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromedriver path: C:\\Users\\49176\\OneDrive\\Desktop\\chromedriver_win32/chromedriver.exe\n",
      "listing of houses on page  1 is 40\n",
      "------calculations house links done--------\n",
      "-----dataframe crated ------\n",
      "Number of unique properties per  page 40\n",
      "Number of unique properties on all  pages 40\n",
      "Number of properties per type of the ad   \n",
      "For sale             37\n",
      "For sale by owner     3\n",
      "Name: ad_type, dtype: int64\n",
      "        \n",
      "Number of properties per company/broker  \n",
      "Property Owner                       3\n",
      "Joelle Pergolotti                    2\n",
      "Elayne Reimer                        2\n",
      "Louis Belisario                      1\n",
      "Keith Jacoby                         1\n",
      "Danielle Stout                       1\n",
      "Jorge Mendoza                        1\n",
      "Kim Mc Keller                        1\n",
      "Robyn Diament                        1\n",
      "Amy Williamson                       1\n",
      "Nicholas Venturini                   1\n",
      "Karen Cantor                         1\n",
      "Eva Penson                           1\n",
      "Ryan Stenta at Eklund|Gomes Team     1\n",
      "Josh Rubin                           1\n",
      "Michael S. Rastegar                  1\n",
      "Richard J Steinberg                  1\n",
      "Craig Dix                            1\n",
      "Alina Yukhtman                       1\n",
      "Phyllis Pei                          1\n",
      "Kristina Gershteyn                   1\n",
      "Dan Sholomon                         1\n",
      "Vanessa Villanueva                   1\n",
      "Sandra Balan                         1\n",
      "Leora Blumberg-Rubinstein            1\n",
      "Harjot Kaur Nayar                    1\n",
      "Jonathan Tauzowicz                   1\n",
      "Paula Del Nunzio                     1\n",
      "Carrie Chiang                        1\n",
      "Raymond Macygin                      1\n",
      "Tali Geva                            1\n",
      "William Falu                         1\n",
      "Hermi Aquino                         1\n",
      "joshua harris                        1\n",
      "Ayleen Aybar                         1\n",
      "Justin Martinez                      1\n",
      "Name: agent, dtype: int64\n",
      "Average price (in total): $11706434.875 \n",
      "Average price per sq.ft: $2717.7812 \n",
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Number of unique properties per  page ': 40,\n",
       " 'Number of properties per page ': 40,\n",
       " 'Number of properties per type of the ad   ': For sale             37\n",
       " For sale by owner     3\n",
       " Name: ad_type, dtype: int64,\n",
       " 'Number of properties per company/broker  ': Property Owner                       3\n",
       " Joelle Pergolotti                    2\n",
       " Elayne Reimer                        2\n",
       " Louis Belisario                      1\n",
       " Keith Jacoby                         1\n",
       " Danielle Stout                       1\n",
       " Jorge Mendoza                        1\n",
       " Kim Mc Keller                        1\n",
       " Robyn Diament                        1\n",
       " Amy Williamson                       1\n",
       " Nicholas Venturini                   1\n",
       " Karen Cantor                         1\n",
       " Eva Penson                           1\n",
       " Ryan Stenta at Eklund|Gomes Team     1\n",
       " Josh Rubin                           1\n",
       " Michael S. Rastegar                  1\n",
       " Richard J Steinberg                  1\n",
       " Craig Dix                            1\n",
       " Alina Yukhtman                       1\n",
       " Phyllis Pei                          1\n",
       " Kristina Gershteyn                   1\n",
       " Dan Sholomon                         1\n",
       " Vanessa Villanueva                   1\n",
       " Sandra Balan                         1\n",
       " Leora Blumberg-Rubinstein            1\n",
       " Harjot Kaur Nayar                    1\n",
       " Jonathan Tauzowicz                   1\n",
       " Paula Del Nunzio                     1\n",
       " Carrie Chiang                        1\n",
       " Raymond Macygin                      1\n",
       " Tali Geva                            1\n",
       " William Falu                         1\n",
       " Hermi Aquino                         1\n",
       " joshua harris                        1\n",
       " Ayleen Aybar                         1\n",
       " Justin Martinez                      1\n",
       " Name: agent, dtype: int64,\n",
       " 'Average price (in total)$: ': 11706434.875,\n",
       " 'Average price per sq.ft$: ': 2717.7812}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromedriver = r\"C:\\Users\\49176\\OneDrive\\Desktop\\chromedriver_win32/chromedriver.exe\" # path to the chromedriver executable\n",
    "chromedriver = os.path.expanduser(chromedriver)\n",
    "sys.path.append(chromedriver)\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "z= ZillowData(driver,chromedriver,'https://www.zillow.com/new-york-ny/')\n",
    "df=z.get_all_data(chromedriver,driver,pages=1)\n",
    "z.stat_of_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listings on 25 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedroom</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>size</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>zillow_days</th>\n",
       "      <th>views</th>\n",
       "      <th>price</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>company</th>\n",
       "      <th>agent</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>100 W 57th St #11R New York NY 10019</td>\n",
       "      <td>New York</td>\n",
       "      <td>190</td>\n",
       "      <td>41,236</td>\n",
       "      <td>215,000</td>\n",
       "      <td>For sale</td>\n",
       "      <td>Douglas Elliman</td>\n",
       "      <td>Phyllis Pei</td>\n",
       "      <td>https://www.zillow.com/homedetails/100-W-57th-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>100 W 57th St APT 5R New York NY 10019</td>\n",
       "      <td>New York</td>\n",
       "      <td>162</td>\n",
       "      <td>8,479</td>\n",
       "      <td>185,000</td>\n",
       "      <td>For sale</td>\n",
       "      <td>Pergolotti Realty 917-415-6609</td>\n",
       "      <td>Joelle Pergolotti</td>\n",
       "      <td>https://www.zillow.com/homedetails/100-W-57th-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2,268</td>\n",
       "      <td>14 W 184th St Bronx NY 10468</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>23</td>\n",
       "      <td>10,499</td>\n",
       "      <td>399,000</td>\n",
       "      <td>For sale</td>\n",
       "      <td>RE/MAX Distinguished Hms.&amp;Prop 914-346-8255</td>\n",
       "      <td>Hermi Aquino</td>\n",
       "      <td>https://www.zillow.com/homedetails/14-W-184th-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1,800</td>\n",
       "      <td>303 E 57th St APT 32B New York NY 10022</td>\n",
       "      <td>New York</td>\n",
       "      <td>46</td>\n",
       "      <td>43,519</td>\n",
       "      <td>445,000</td>\n",
       "      <td>For sale</td>\n",
       "      <td>Brown Harris Stevens 212-381-3372</td>\n",
       "      <td>Elayne Reimer</td>\n",
       "      <td>https://www.zillow.com/homedetails/303-E-57th-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7,130</td>\n",
       "      <td>111 W 57th St PENTHOUSE 72 New York NY 10019</td>\n",
       "      <td>New York</td>\n",
       "      <td>148</td>\n",
       "      <td>42,892</td>\n",
       "      <td>66,000,000</td>\n",
       "      <td>For sale</td>\n",
       "      <td>Douglas Elliman 212-203-5401</td>\n",
       "      <td>Amy Williamson</td>\n",
       "      <td>https://www.zillow.com/homedetails/111-W-57th-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bedroom bathroom   size                                       address  \\\n",
       "0       1        1    900          100 W 57th St #11R New York NY 10019   \n",
       "1       1        1    900        100 W 57th St APT 5R New York NY 10019   \n",
       "2       5        4  2,268                  14 W 184th St Bronx NY 10468   \n",
       "3       2        3  1,800       303 E 57th St APT 32B New York NY 10022   \n",
       "4       4        6  7,130  111 W 57th St PENTHOUSE 72 New York NY 10019   \n",
       "\n",
       "       city zillow_days   views       price   ad_type  \\\n",
       "0  New York         190  41,236     215,000  For sale   \n",
       "1  New York         162   8,479     185,000  For sale   \n",
       "2     Bronx          23  10,499     399,000  For sale   \n",
       "3  New York          46  43,519     445,000  For sale   \n",
       "4  New York         148  42,892  66,000,000  For sale   \n",
       "\n",
       "                                       company               agent  \\\n",
       "0                              Douglas Elliman        Phyllis Pei    \n",
       "1               Pergolotti Realty 917-415-6609  Joelle Pergolotti    \n",
       "2  RE/MAX Distinguished Hms.&Prop 914-346-8255       Hermi Aquino    \n",
       "3            Brown Harris Stevens 212-381-3372      Elayne Reimer    \n",
       "4                 Douglas Elliman 212-203-5401     Amy Williamson    \n",
       "\n",
       "                                                link  \n",
       "0  https://www.zillow.com/homedetails/100-W-57th-...  \n",
       "1  https://www.zillow.com/homedetails/100-W-57th-...  \n",
       "2  https://www.zillow.com/homedetails/14-W-184th-...  \n",
       "3  https://www.zillow.com/homedetails/303-E-57th-...  \n",
       "4  https://www.zillow.com/homedetails/111-W-57th-...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listing on all the 25 pages\n",
    "# load the data from saved pickle \n",
    "with open('zillow_data_25Pages.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "#create dataframe for listings on 25 pages\n",
    "df=pd.DataFrame([j for i in data for j in i])\n",
    "#define column\n",
    "columns=['bedroom','bathroom','size','address','city','zillow_days','views','price','ad_type','company','agent','link']\n",
    "df.columns=columns\n",
    "#show data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique properties per  page 40\n",
      "Number of unique properties on all  pages 800\n",
      "Number of properties per type of the ad   \n",
      "For sale             956\n",
      "For sale by owner     31\n",
      "New construction       7\n",
      "Foreclosure            2\n",
      "Contingent             1\n",
      "Pending                1\n",
      "Lot/land               1\n",
      "Auction                1\n",
      "Name: ad_type, dtype: int64\n",
      "        \n",
      "Number of properties per company/broker  \n",
      "Property Owner                          31\n",
      "Joelle Pergolotti                       24\n",
      "Elayne Reimer                           15\n",
      "Eric Lee                                13\n",
      "Keystone Realty Of Greater New York     10\n",
      "                                        ..\n",
      "Nicholas Isra                            1\n",
      "Deedee Weiss                             1\n",
      "Dave Constantino                         1\n",
      "Deanna Kory                              1\n",
      "Judith McKenna                           1\n",
      "Name: agent, Length: 650, dtype: int64\n",
      "Average price (in total): $5535262.854 \n",
      "Average price per sq.ft: $1127.9802 \n",
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Number of unique properties per  page ': 40,\n",
       " 'Number of properties per page ': 800,\n",
       " 'Number of properties per type of the ad   ': For sale             956\n",
       " For sale by owner     31\n",
       " New construction       7\n",
       " Foreclosure            2\n",
       " Contingent             1\n",
       " Pending                1\n",
       " Lot/land               1\n",
       " Auction                1\n",
       " Name: ad_type, dtype: int64,\n",
       " 'Number of properties per company/broker  ': Property Owner                          31\n",
       " Joelle Pergolotti                       24\n",
       " Elayne Reimer                           15\n",
       " Eric Lee                                13\n",
       " Keystone Realty Of Greater New York     10\n",
       "                                         ..\n",
       " Nicholas Isra                            1\n",
       " Deedee Weiss                             1\n",
       " Dave Constantino                         1\n",
       " Deanna Kory                              1\n",
       " Judith McKenna                           1\n",
       " Name: agent, Length: 650, dtype: int64,\n",
       " 'Average price (in total)$: ': 5535262.854,\n",
       " 'Average price per sq.ft$: ': 1127.9802}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.stat_of_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
